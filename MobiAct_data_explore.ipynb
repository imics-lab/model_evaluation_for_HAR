{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MobiAct_data_explore.ipynb","provenance":[],"mount_file_id":"1EyTMlTXM8lImiCO3hsDg_59bPohkpb9l","authorship_tag":"ABX9TyNeZY1zFbXJQ7lo3B08NuDr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"UXgow-O8JKvK"},"source":["# Load X, y, sub numpy arrays, process, and train a 1D CNN\n","Loads X, y, sub numpy arrays. \n","\n","Processes into train, test, and validation if needed.\n","\n","This code was used to run the frequency, kernel size, and\n","total versus component accel data experiments.\n","\n","Author:  Lee B. Hinkle, [IMICS Lab](https://imics.wp.txstate.edu/), Texas State University, 2021\n","\n","<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>.\n","\n","TODO:\n","* Timing should be inside model but must be passed back out"]},{"cell_type":"code","metadata":{"id":"q6H67o-YARCx","executionInfo":{"status":"ok","timestamp":1618604485720,"user_tz":300,"elapsed":385,"user":{"displayName":"Lee Hinkle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgewSVTK-UUEEP0ihHQARBRqOb4YrK-IiepxHiI=s64","userId":"00071704663307985880"}}},"source":["import os\n","import shutil #https://docs.python.org/3/library/shutil.html\n","from shutil import unpack_archive # to unzip\n","#from shutil import make_archive # to create zip for storage\n","import requests #for downloading zip file\n","import glob # to generate lists of files in directory - unix style pathnames\n","#from scipy import io #for loadmat, matlab conversion\n","import pandas as pd\n","import numpy as np\n","#import matplotlib.pyplot as plt # for plotting - pandas uses matplotlib\n","from tabulate import tabulate # for verbose tables\n","from keras.utils import to_categorical # for one-hot encoding\n","import matplotlib.pyplot as plt # for plotting training curves\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import GroupKFold\n","from tensorflow import keras #added to save model\n","from tensorflow.keras import layers #format matches MNIST example\n","# to measure and display training time\n","import time\n","from datetime import timedelta\n","from sklearn.preprocessing import LabelEncoder # for one-hot encoding\n","from sklearn.preprocessing import OneHotEncoder # for one-hot encoding\n","#imports for computing and displaying output metrics\n","import seaborn as sns\n","import pandas as pd\n","import numpy as np\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"A_x92yC2dpq8","executionInfo":{"status":"ok","timestamp":1618604488598,"user_tz":300,"elapsed":499,"user":{"displayName":"Lee Hinkle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgewSVTK-UUEEP0ihHQARBRqOb4YrK-IiepxHiI=s64","userId":"00071704663307985880"}}},"source":["verbose = False #@param {type:\"boolean\"}\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jVWEsG9zVT_E","executionInfo":{"status":"ok","timestamp":1618604489364,"user_tz":300,"elapsed":388,"user":{"displayName":"Lee Hinkle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgewSVTK-UUEEP0ihHQARBRqOb4YrK-IiepxHiI=s64","userId":"00071704663307985880"}},"outputId":"1b9b3ba8-79b2-40e9-cd63-876773a65863"},"source":["#create function to toggle print level.  Note: python logging may be better\n","#credit https://stackoverflow.com/users/416467/kindall\n","#https://stackoverflow.com/questions/5980042/how-to-implement-the-verbose-or-v-option-into-a-script\n","if verbose:\n","    print(\"Verbose mode on\")\n","    def vprint(*args):\n","        # Print each argument separately so caller doesn't need to\n","        # stuff everything to be printed into a single string\n","        for arg in args:\n","           print (arg, end=\" \")\n","        print()\n","else: \n","    print(\"Verbose mode off\")  \n","    vprint = lambda *a: None      # do-nothing function"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Verbose mode off\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vCowlgvcNmSg","executionInfo":{"status":"ok","timestamp":1618604490771,"user_tz":300,"elapsed":388,"user":{"displayName":"Lee Hinkle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgewSVTK-UUEEP0ihHQARBRqOb4YrK-IiepxHiI=s64","userId":"00071704663307985880"}}},"source":["#Helpful functions especially inside colab\n","from requests import get\n","def what_is_my_name():\n","    \"\"\"returns the name of the running colab ipynb file\"\"\"\n","    #code is readily available on web - not original\n","    my_name = get('http://172.28.0.2:9000/api/sessions').json()[0]['name']\n","    return my_name\n","#start output file with unique name - important for colab runs\n","def start_logfile(base_name = \"unnamed\", first_line = \"nothing here\"):\n","    \"\"\"creates file in result_dir, writes first_line, environment info.\n","    Returns full filename concatenation of path, base_name, current UTC time\"\"\"\n","    result_dir = '/content/drive/My Drive/Colab_Run_Results'\n","    timestamp = time.strftime('%b-%d-%Y_%H%M', time.localtime()) #UTC time\n","    log_fname = base_name +'_'+timestamp\n","    full_log_fname = result_dir+'/'+log_fname+'.txt'\n","    print(\"Starting text logfile \",full_log_fname)\n","    with open(full_log_fname, \"w\") as file_object:\n","        header = first_line + '\\n'\n","        header += full_log_fname +'\\n'\n","        header += 'Generated by ' + what_is_my_name() + '\\n'\n","        cpu_model = !grep 'model name' /proc/cpuinfo\n","        header += 'CPU1: ' + cpu_model[0] + '\\n'\n","        header += 'CPU2: ' + cpu_model[1] + '\\n'\n","        gpu_info = !nvidia-smi --query-gpu=gpu_name,driver_version,memory.total --format=csv\n","        header += 'GPU: ' + str(gpu_info[1]) + '\\n'\n","        file_object.write(header)\n","    return full_log_fname\n","#Helper function since frequently checking and logging shapes\n","#credit https://stackoverflow.com/users/4944093/george-petrov for name method\n","def namestr(obj, namespace):\n","    return [name for name in namespace if namespace[name] is obj]\n","def get_shapes(np_arr_list):\n","    \"\"\"Returns text, each line is shape and dtype for numpy array in list\n","       example: print(get_shapes([X_train, X_test, y_train, y_test]))\"\"\"\n","    shapes = \"\"\n","    for i in np_arr_list:\n","        my_name = namestr(i,globals())\n","        shapes += (my_name[0] + \" shape is \" + str(i.shape) \\\n","            + \" data type is \" + str(i.dtype) + \"\\n\")\n","    return shapes"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"f04oCLk53KMa","executionInfo":{"status":"ok","timestamp":1618604491778,"user_tz":300,"elapsed":256,"user":{"displayName":"Lee Hinkle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgewSVTK-UUEEP0ihHQARBRqOb4YrK-IiepxHiI=s64","userId":"00071704663307985880"}}},"source":["def process_xysub (input_dir = 'not_set',use_xyz = False):\n","    \"\"\"inputs X,y,sub numpy arrays from input_dir, use_xyz = true returns\n","    component acceleration, false returns total acceleration,\n","    one-hot encodes y\"\"\"\n","    process_info = 'arrays loaded from'\n","    process_info += input_dir + '\\n'\n","    X = np.load(input_dir + '/' + 'X.npy')\n","    y = np.load(input_dir + '/' +'y.npy')\n","    sub = np.load(input_dir + '/' +'sub.npy')\n","    #TODO Load info file as well\n","    #No clue what I cannot call get_shapes inside method\n","    #generates list index out of range error, works fine in scratch cell\n","    #shapes = get_shapes([X,y,sub])\n","    #print(shapes)\n","    #process_info += \"Starting shape of loaded files\\n\" + shapes\n","    # Drop either the three component accel or the total_accel\n","    # TODO should name numpy columns and drop by name for versatility\n","    # this assumes ['accel_x','accel_y','accel_z','total_accel']\n","    if (use_xyz):\n","        process_info += \"Using xyz component accel, deleting total_accel from X\\n\"\n","        X = np.delete(X, 3, 2) # delete column 4 along axis 2\n","    else:\n","        process_info += \"Using total component accel, deleting accel_x/y/z from X\\n\"\n","        X = np.delete(X, [0,1,2],2) # delete columns 1-3 along axis 2\n","    #One-Hot-Encode y...there must be a better way when starting with strings\n","    #https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/\n","\n","    if (y.shape[1]==1):\n","        # integer encode\n","        y_vector = np.ravel(y) #encoder won't take column vector\n","        le = LabelEncoder()\n","        integer_encoded = le.fit_transform(y_vector) #convert from string to int\n","        name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n","        process_info += \"One Hot Encoding:\" + str(name_mapping) +\"\\n\"\n","        onehot_encoder = OneHotEncoder(sparse=False)\n","        integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n","        onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n","        y=onehot_encoded\n","    else:\n","        print (\"y.shape[1] is not one, appears to be encoded already. Skipping\")\n","    return X,y,sub,process_info"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"wWipKZmdLMmu","executionInfo":{"status":"ok","timestamp":1618604492849,"user_tz":300,"elapsed":479,"user":{"displayName":"Lee Hinkle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgewSVTK-UUEEP0ihHQARBRqOb4YrK-IiepxHiI=s64","userId":"00071704663307985880"}}},"source":["def split_sub_dict (X,y,sub):\n","    \"\"\"inputs X,y,sub numpy arrays and splits into train, validate, and test\n","    based on the split_sub dict which is internal for now\"\"\"\n","    split_info = \"manual split using pre-selected subjects\\n\"\n","    split_subj = {'train_subj':[2,4,5,9,10,16,18,20,23,24,26,27,28,32,34,35,\n","                                    36,38,42,45,46,47,48,49,50,51,52,53,54,57],\n","                    'validation_subj':[3,6,8,11,12,22,37,40,43,56],\n","                    'test_subj':[7,19,21,25,29,33,39,41,44,55]}\n","\n","    train_index = np.empty([1],dtype=int) #empty list\n","    #vprint won't work with the end arg to suppress return\n","    #print(\"\\nTrain Group adding subjects: \", end =\" \")\n","    split_info += \"\\nTrain Group subjects: \"\n","    for my_sub in split_subj['train_subj']:\n","        #print(my_sub, end =\" \")\n","        split_info += str(my_sub) + \",\"\n","        #print(np.argwhere(sub == my_sub)[:,0])\n","        train_index = np.concatenate((train_index, np.argwhere(sub == my_sub)[:,0]))\n","\n","    validation_index = np.empty([1],dtype=int) #empty list\n","    #print(\"\\nValidation Group adding subjects:\", end =\" \")\n","    split_info += \"\\nValidation Group subjects: \"\n","    for my_sub in split_subj['validation_subj']:\n","        #print(my_sub, end =\" \")\n","        split_info += str(my_sub) + \",\"\n","        validation_index = np.concatenate((validation_index, np.argwhere(sub == my_sub)[:,0]))\n","\n","    test_index = np.empty([1],dtype=int) #empty list\n","    #print(\"\\nTest Group adding subjects:\", end =\" \")\n","    split_info += \"\\nTest Group subjects: \"\n","    for my_sub in split_subj['test_subj']:\n","        #print(my_sub, end =\" \")\n","        split_info += str(my_sub) + \",\"\n","        test_index = np.concatenate((test_index, np.argwhere(sub == my_sub)[:,0]))\n","\n","    #print(\"\\n\")\n","    split_info += \"\\n\"\n","    #delete first row placeholders\n","    train_index = np.delete(train_index, (0), axis=0) \n","    validation_index = np.delete(validation_index, (0), axis=0) \n","    test_index = np.delete(test_index, (0), axis=0)\n","\n","    X_train, X_test, X_validation = X[train_index], X[test_index], X[validation_index]\n","    y_train, y_test, y_validation = y[train_index], y[test_index], y[validation_index]\n","\n","    return  X_train, y_train, X_validation, y_validation, X_test, y_test, split_info"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"IKTPAbXS3ZKq","executionInfo":{"status":"ok","timestamp":1618604494861,"user_tz":300,"elapsed":631,"user":{"displayName":"Lee Hinkle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgewSVTK-UUEEP0ihHQARBRqOb4YrK-IiepxHiI=s64","userId":"00071704663307985880"}}},"source":["#def evaluate_model(trainX, trainy, validateX, validatey, testX, testy):\n","#different topology and good article here\n","#https://blog.goodaudience.com/introduction-to-1d-convolutional-neural-networks-in-keras-for-time-sequences-3a7ff801a2cf\n","def evaluate_model(trainX,trainy, validationX, validationy, \n","                    batch_size=32, num_epochs=200, kernel_size = 20):\n","    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n","    model = keras.Sequential(\n","        [\n","        keras.Input(shape=(n_timesteps,n_features)),\n","        layers.Conv1D(filters=50, kernel_size = kernel_size, activation='relu'),\n","        layers.Conv1D(filters=50, kernel_size = kernel_size, activation='relu'),\n","        layers.Dropout(0.5),\n","        layers.MaxPooling1D(pool_size=2),\n","        layers.Flatten(),\n","        layers.Dense(100, activation='relu'),\n","        layers.Dense(n_outputs, activation='softmax')\n","        ]\n","    )\n","    #model.summary()\n","    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","    start_time = time.time()\n","    history = model.fit(\n","        trainX,trainy,\n","        steps_per_epoch=trainX.shape[1]//batch_size,\n","        epochs=num_epochs,\n","        verbose = 0, #0 = silent, 1 = progress bar, 2 = one line per epoch.       \n","        validation_data=(validationX,validationy),\n","        validation_steps=validationX.shape[1]//batch_size)\n","    end_time = time.time()\n","    train_time = timedelta(seconds=(end_time - start_time))\n","    #print('Training time =',(np.str(train_time).split(\".\")[0]), 'HH:MM:SS')\n","    model.save('my_1D_CNN_model')\n","    return history"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"OlPIcyEIl2--","executionInfo":{"status":"ok","timestamp":1618604495782,"user_tz":300,"elapsed":533,"user":{"displayName":"Lee Hinkle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgewSVTK-UUEEP0ihHQARBRqOb4YrK-IiepxHiI=s64","userId":"00071704663307985880"}}},"source":["def run_model(testX, testy,batch_size = 32):\n","    model = keras.models.load_model('my_1D_CNN_model')\n","    start_time = time.time()\n","    predictions = model.predict(testX, verbose=0,batch_size=32)\n","    end_time = time.time()\n","    eval_time = timedelta(seconds=(end_time - start_time))\n","    #print('Eval time =',(np.str(eval_time).split(\".\")[0]), 'HH:MM:SS')\n","\n","    #must use values not one-hot encoding, use argmax to convert\n","    y_pred = np.argmax(predictions, axis=-1) # axis=-1 means last axis\n","    y_test = np.argmax(testy, axis=-1)\n","\n","    #print(classification_report(y_test, y_pred, target_names=ACT))\n","    #cm = confusion_matrix(y_test, y_pred)\n","    #print(cm)\n","    return (accuracy_score(y_test, y_pred))"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"rZhDNNC22wsR","executionInfo":{"status":"ok","timestamp":1618604519946,"user_tz":300,"elapsed":339,"user":{"displayName":"Lee Hinkle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgewSVTK-UUEEP0ihHQARBRqOb4YrK-IiepxHiI=s64","userId":"00071704663307985880"}}},"source":["#Just parking this here processing full list takes a several days on CPU instance\n","base_dir = '/content/drive/My Drive/Processed_Datasets/mobiact_xys/'\n","# filename, kernel size (1 second worth), batch size\n","worklist = [[base_dir + 'mobiact_xys_5Hz_3s', 5, 8],\n","          [base_dir + 'mobiact_xys_5Hz_3s', 5, 8], # first run has odd time\n","          [base_dir + 'mobiact_xys_10Hz_3s', 10, 8],\n","          [base_dir + 'mobiact_xys_15Hz_3s', 15, 8],\n","          [base_dir + 'mobiact_xys_20Hz_3s', 20, 8],\n","          [base_dir + 'mobiact_xys_25Hz_3s', 25, 8],\n","          [base_dir + 'mobiact_xys_30Hz_3s', 30, 8],\n","          [base_dir + 'mobiact_xys_40Hz_3s', 40, 8],\n","          [base_dir + 'mobiact_xys_60Hz_3s', 60, 8],\n","          [base_dir + 'mobiact_xys_80Hz_3s', 80, 8],\n","          [base_dir + 'mobiact_xys_100Hz_3s', 100, 8],\n","          [base_dir + 'mobiact_xys_no_resample_3s', 100, 8]]\n","\n","worklist = [[base_dir + 'mobiact_xys_80Hz_3s', 80, 8],\n","          [base_dir + 'mobiact_xys_100Hz_3s', 100, 8],\n","          [base_dir + 'mobiact_xys_no_resample_3s', 100, 8]]"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"miHhyQmUXinS"},"source":["#The big loop"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AXvyoe-EWJsn","executionInfo":{"status":"ok","timestamp":1618604766686,"user_tz":300,"elapsed":76442,"user":{"displayName":"Lee Hinkle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgewSVTK-UUEEP0ihHQARBRqOb4YrK-IiepxHiI=s64","userId":"00071704663307985880"}},"outputId":"ce943013-7c32-4ed2-e45e-16b7710df8a9"},"source":["full_log_fname = start_logfile(base_name = \"MobiAct_Resample_CPU\", \n","                                first_line = \"resample batch size experiments, CPU instance, uniform batch size of 8\")\n","base_dir = '/content/drive/My Drive/Processed_Datasets/mobiact_xys/'\n","ACT = ['JOG','JUM','STD','STN','STU','WAL'] #MobiAct specific\n","# filename, kernel size (1 second worth), batch size\n","worklist = [[base_dir + 'mobiact_xys_20Hz_3s', 20, 16]]\n","\n","gpu_info = !nvidia-smi --query-gpu=gpu_name,driver_version,memory.total --format=csv\n","print('GPU: ' + str(gpu_info[1]) + '\\n')\n","for x in worklist:\n","    kernel_size = x[1]\n","    batch_size = x[2]\n","    num_epochs = 200\n","    pass_info = \"--- processing \" + str(x[0]) + \"\\n\"\n","    pass_info += \"--- batch_size = \" + str(batch_size)\n","    pass_info += \" kernel_size = \" + str(kernel_size)\n","    pass_info += \" num_epochs = \" + str(num_epochs) + \"\\n\"\n","    print (pass_info)\n","    with open(full_log_fname, \"a\") as file_object:\n","            file_object.write(pass_info)\n","    X,y,sub,src_info = process_xysub (input_dir = x[0], use_xyz = False)\n","    X_train, y_train, X_validation, y_validation, X_test, y_test, split_info = split_sub_dict (X,y,sub)\n","    #print(get_shapes([X_train, y_train, X_validation, y_validation, X_test, y_test]))\n","\n","    repeats = 5;\n","    #for my_split in my_full_list:\n","    for i in range(1):\n","        for repeat_num in range(repeats):  #rerun current config\n","            # train model\n","            # timing should be in evaluate - but having issues passing back\n","            start_time = time.time()\n","            history = evaluate_model(X_train, y_train, X_validation, y_validation,\n","                                    batch_size, num_epochs, kernel_size)\n","            end_time = time.time()\n","            ttime = str(timedelta(seconds=(end_time - start_time)).total_seconds())\n","            # run model\n","            acc = run_model(X_test, y_test)\n","            if (repeat_num == 0):\n","                acc_string = \"acc = [\"+'{0:.3f}'.format(acc)\n","                ttime_string = \"ttime = [\" + ttime\n","            else:\n","                acc_string += ',' + '{0:.3f}'.format(acc)\n","                ttime_string += ',' + ttime\n","        acc_string += ']\\n'\n","        ttime_string += ']\\n'\n","        print(x[0])\n","        print (ttime_string)\n","        print (acc_string)\n","        with open(full_log_fname, \"a\") as file_object:\n","            file_object.write(ttime_string)\n","            file_object.write(acc_string) "],"execution_count":14,"outputs":[{"output_type":"stream","text":["Starting text logfile  /content/drive/My Drive/Colab_Run_Results/MobiAct_Resample_CPU_Apr-16-2021_2024.txt\n","GPU: Tesla V100-SXM2-16GB, 460.32.03, 16160 MiB\n","\n","--- processing /content/drive/My Drive/Processed_Datasets/mobiact_xys/mobiact_xys_20Hz_3s\n","--- batch_size = 16 kernel_size = 20 num_epochs = 200\n","\n","INFO:tensorflow:Assets written to: my_1D_CNN_model/assets\n","INFO:tensorflow:Assets written to: my_1D_CNN_model/assets\n","INFO:tensorflow:Assets written to: my_1D_CNN_model/assets\n","INFO:tensorflow:Assets written to: my_1D_CNN_model/assets\n","INFO:tensorflow:Assets written to: my_1D_CNN_model/assets\n","/content/drive/My Drive/Processed_Datasets/mobiact_xys/mobiact_xys_20Hz_3s\n","ttime = [14.431182,13.847657,13.894559,13.920548,13.804549]\n","\n","acc = [0.980,0.976,0.979,0.961,0.980]\n","\n","\n","Final Validation Accuracy: 0.993\n"],"name":"stdout"}]}]}